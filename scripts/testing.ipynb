{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bdd2da6",
   "metadata": {},
   "source": [
    "EXTRACTING TEXT FROM PDF FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69715600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Second Edition 2024 Financial Stability Review_Final_.pdf\n",
      "Extracted sarb-2024-25.pdf\n",
      "Extracted MPROCT2024INTERNET.pdf\n",
      "Extracted Monetary Policy Review April 2025.pdf\n",
      "Extracted First Edition 2025 Financial Stability Review_1.pdf\n",
      "Extracted SARB Annual Financial Statements 2023-24.pdf\n",
      "Extracted Tax chronology 2025 Final.pdf\n"
     ]
    }
   ],
   "source": [
    "# batch_pdf_to_text_pypdf.py\n",
    "from pypdf import PdfReader\n",
    "import os\n",
    "\n",
    "# Input and output directories\n",
    "input_dir = \"../data/raw/SARB\"\n",
    "output_dir = \"../data/text/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop over all PDFs in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(input_dir, filename)\n",
    "        text_path = os.path.join(output_dir, filename.replace(\".pdf\", \".txt\"))\n",
    "\n",
    "        all_text = \"\"\n",
    "        reader = PdfReader(pdf_path)\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:  # skip pages with no extractable text\n",
    "                all_text += page_text + \"\\n\"\n",
    "\n",
    "        # Write extracted text to a .txt file\n",
    "        with open(text_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(all_text)\n",
    "\n",
    "        print(f\"Extracted {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee1f66",
   "metadata": {},
   "source": [
    "CLEANING TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f415531d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned MPROCT2024INTERNET.txt\n",
      "Cleaned Second Edition 2024 Financial Stability Review_Final_.txt\n",
      "Cleaned sarb-2024-25.txt\n",
      "Cleaned Monetary Policy Review April 2025.txt\n",
      "Cleaned Tax chronology 2025 Final.txt\n",
      "Cleaned SARB Annual Financial Statements 2023-24.txt\n",
      "Cleaned First Edition 2025 Financial Stability Review_1.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# --- Cleaning & normalization function ---\n",
    "def clean_and_normalize(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove headers/footers/page numbers\n",
    "    text = re.sub(r'page \\d+', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'sarb.*report', '', text, flags=re.IGNORECASE)  # adjust pattern to your reports\n",
    "    \n",
    "    # Remove copyright and boilerplate\n",
    "    text = re.sub(r'[©®]', '', text)\n",
    "    text = re.sub(r'south african reserve bank', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'all rights reserved', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove multiple newlines and spaces\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = re.sub(r'[ ]+', ' ', text)\n",
    "    \n",
    "    # Strip leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# --- Batch processing ---\n",
    "input_dir = \"../data/text/\"\n",
    "output_dir = \"../data/clean/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(os.path.join(input_dir, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        cleaned_text = clean_and_normalize(text)\n",
    "\n",
    "        # Save cleaned text\n",
    "        with open(os.path.join(output_dir, filename), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(cleaned_text)  # write tokenized version as a single string\n",
    "        \n",
    "        print(f\"Cleaned {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
